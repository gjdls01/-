{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f763f4b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk.lm import MLE\n",
    "import json\n",
    "import konlpy\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "with open(\"/Users/infected4098/Downloads/Sample/origin/BWSC217000050061.json\", \"r\") as f:\n",
    "    json_data=json.load(f)\n",
    "#print(json.dumps(json_data))\n",
    "kor_text=json_data[\"SJML\"][\"text\"][1][\"content\"]\n",
    "type(kor_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50ef4187",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_1=r\"\\([^)]*\\)\"\n",
    "pattern_2=r\"\\.{2}\"\n",
    "def preprocess_sent(lst_text):\n",
    "    wholelist=[]\n",
    "    buf=str()\n",
    "    subkor_1=re.sub(pattern=pattern_1, repl=\"\", string=lst_text)\n",
    "    subkor_2=re.sub(pattern=pattern_2, repl=\"\", string=subkor_1)\n",
    "    clear_list=re.compile(\"[가-힣]+|\\.{1}\").findall(subkor_2)\n",
    "    for word in clear_list:\n",
    "        if word==\".\":\n",
    "            buf+=(word+\" \")\n",
    "            wholelist.append(buf)\n",
    "            buf=str()\n",
    "        \n",
    "        else:\n",
    "            buf+=(word+\" \")\n",
    "    return wholelist\n",
    "\n",
    "\n",
    "okt=Okt()\n",
    "lst_sent=preprocess_sent(kor_text)\n",
    "def sent_to_morph(lst_sent):\n",
    "    double_list=[]\n",
    "    for sentence in lst_sent:\n",
    "        listed=okt.morphs(sentence)\n",
    "        double_list.append(listed)\n",
    "    return double_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea5c82cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['업', '그렉', '터', '는', '구로구', '가', '추진', '하는', '스마트', '시티', '마스터플랜', '및', '중', '장기', '로드맵', '마련', '을', '위', '한', '정보', '전략', '계획', '수립', '주', '계약', '자로', '선정', '됐다고', '일', '밝혔다', '.'], ['이', '사업', '은', '국토부', '와', '과기부', '등', '범', '정부', '차원', '에서', '추진', '중인', '스마트', '시티', '국가', '사업', '과', '연', '계해', '풀', '뿌리', '지자체', '최초', '로', '구로구', '에', '특화된', '스마트', '시티', '플랫폼', '을', '구축', '하는', '것', '이다', '.'], ['복지', '와', '안전', '녹색', '도시', '교육', '및', '문화', '등', '도시', '지표', '산출', '과', '스마트', '시티', '도시', '아카이브', '서비스', '를', '개발', '구로', '구민', '의', '삶', '의', '질', '과', '가치', '를', '높인다', '.'], ['그렉', '터', '는', '여', '년', '간', '스마트', '시티', '와', '스마트홈', '프로젝트', '를', '통해', '축적', '한', '노하우', '를', '토대', '로', '향후', '년', '간', '진행', '할', '구로구', '스마트', '시티', '모델', '을', '설계', '한', '다', '.'], ['구로구', '자', '가망', '과', '서비스', '고도화', '등', '지속', '가능한', '차세대', '스마트', '시티', '플랫폼', '로드맵', '을', '제시', '하는', '등', '구로', '구청', '데이터', '거버넌스', '전략', '의', '핵심', '역할', '을', '수행', '한다', '.'], ['그렉', '터', '는', '또', '구로구', '풀', '뿌리', '스마트', '시티', '를', '위', '한', '도시', '아카이브', '플랫폼', '을', '설계', '및', '개발', '해', '구로', '구청', '에서', '진행중', '인', '여개', '스마트', '시티', '와', '스마트홈', '관련', '프로젝트', '를', '통합', '관리', '하고', '방대한', '도시', '데이터', '와', '시민', '데이터', '를', '축적', '주민', '이', '직접', '참여', '하는', '개방', '형', '스마트', '시티', '모델', '을', '구축', '한다', '.'], ['구로구', '는', '관내', '전역', '에', '와이파이', '망', '과', '사물인터넷', '망', '을', '갖추고', '있다', '.'], ['민선', '기', '핵심', '사업', '중', '하나', '인', '이번', '프로젝트', '를', '통해', '구정', '내부', '프로젝트', '를', '구민', '과', '공유', '하고', '소통', '하는', '주민', '참여', '기반', '스마트', '도시', '서비스', '를', '갖춘다', '.'], ['그렉', '터', '는', '구로구', '망고', '도화', '를', '위해', '기존', '로라', '완망', '뿐', '아니라', '통신', '사', '망', '간', '연', '계', '가', '필수', '라고', '판단', '지난달', '일', '부터', '이', '달초', '까지', '일간', '유관', '기업', '에서', '참신한', '제안', '을', '접수', '구로구', '자', '가망', '고도화', '전략', '을', '수립', '할', '예정', '이다', '.'], ['그렉', '터', '대표', '는', '구로', '구청', '스마트', '시티', '사업', '은', '전국', '최초', '구', '단위', '지자체', '프로젝트', '라며', '사업', '규모', '는', '컴팩트', '한', '반면', '전국', '최고', '기간', '통신망', '과', '인프라', '를', '갖추고', '있어', '단기간', '에', '가시', '적', '사업', '성', '과를', '낼', '것', '으로', '확신', '한다', '고', '강조', '했다', '.'], ['이어', '그', '는', '전국', '지자체', '와', '신도시', '가', '스마트', '시티', '를', '구축', '할', '때', '성공사례', '로', '삼', '을', '수', '있는', '롤모델', '이', '될', '것', '이라고', '덧붙였다', '.'], ['한편', '그렉', '터', '는', '지난', '월', '일', '창립', '한', '한국', '스마트', '휴먼', '테크', '협회', '부회', '장사', '로', '선임', '되는', '등', '전국', '풀', '뿌리', '지자체', '의', '스마트', '시티', '및', '스마트홈', '사업', '화', '와', '인프라', '저변', '확대', '에', '적극', '나서고', '있다', '.']]\n"
     ]
    }
   ],
   "source": [
    "listed=preprocess_sent(kor_text)\n",
    "double=sent_to_morph(listed)\n",
    "print(double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e242651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('<s>',), ('<s>', '업'), ('업',), ('업', '그렉'), ('그렉',), ('그렉', '터'), ('터',), ('터', '는'), ('는',), ('는', '구로구'), ('구로구',), ('구로구', '가'), ('가',), ('가', '추진'), ('추진',), ('추진', '하는'), ('하는',), ('하는', '스마트'), ('스마트',), ('스마트', '시티'), ('시티',), ('시티', '마스터플랜'), ('마스터플랜',), ('마스터플랜', '및'), ('및',), ('및', '중'), ('중',), ('중', '장기'), ('장기',), ('장기', '로드맵'), ('로드맵',), ('로드맵', '마련'), ('마련',), ('마련', '을'), ('을',), ('을', '위'), ('위',), ('위', '한'), ('한',), ('한', '정보'), ('정보',), ('정보', '전략'), ('전략',), ('전략', '계획'), ('계획',), ('계획', '수립'), ('수립',), ('수립', '주'), ('주',), ('주', '계약'), ('계약',), ('계약', '자로'), ('자로',), ('자로', '선정'), ('선정',), ('선정', '됐다고'), ('됐다고',), ('됐다고', '일'), ('일',), ('일', '밝혔다'), ('밝혔다',), ('밝혔다', '.'), ('.',), ('.', '</s>'), ('</s>',)]\n"
     ]
    }
   ],
   "source": [
    "train_data, padded_sents=padded_everygram_pipeline(2, double)\n",
    "for text in train_data:\n",
    "    print(list(text))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5dd6046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2=MLE(3)\n",
    "len(model_2.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d141d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(train_data, padded_sents)\n",
    "len(model_2.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8bcfaf14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.counts[\"시티\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d61dbf40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['삶', '의', '삶', '의', '삶', '의', '핵심', '사업', '은', '국토부']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.generate(10, random_seed=156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9fc0be5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts=[[\"구로\", \"종암\", \"안암\"], [\"안암\", \"사람\", \"구로\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ec9734c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('<s>',), ('<s>', '구로'), ('구로',), ('구로', '종암'), ('종암',), ('종암', '안암'), ('안암',), ('안암', '</s>'), ('</s>',)]\n"
     ]
    }
   ],
   "source": [
    "train_data_t, padded_sents_t=padded_everygram_pipeline(2, texts)\n",
    "#train_data_t=list(train_data_t)\n",
    "padded_sents_t=list(padded_sents_t)\n",
    "\n",
    "for texts in train_data_t:\n",
    "    print(list(texts))\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9c4713a2",
   "metadata": {},
   "source": [
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "80e7481d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', '구로', '종암', '안암', '</s>', '<s>', '안암', '사람', '구로', '</s>']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3=MLE(3)\n",
    "len(model_3.vocab)\n",
    "\n",
    "padded_sents_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e0ba46dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_3.fit(data_gen, padded_sents_t)\n",
    "#len(model_3.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "9f068a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams(double_list, model):\n",
    "    \n",
    "        \n",
    "    train, vocab=padded_everygram_pipeline(2, double_list)\n",
    "    vocab=list(vocab)\n",
    "    \n",
    "    model.fit(train, vocab)\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "9f3118ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_pipeline(stringed_text):\n",
    "    listed=preprocess_sent(stringed_text)\n",
    "    double=sent_to_morph(listed)\n",
    "    \n",
    "    return double\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "97c3ed64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1169590950012207"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "start=time.time()\n",
    "a=new_pipeline(kor_text)\n",
    "end=time.time()\n",
    "end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d5914b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926c4a69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d417afeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntext=[[\"a\", \"b\", \"c\", \"d\"], [\"가\", \"다\", \"a\", \"c\"]]\\n\\ntrain, vocab=padded_everygram_pipeline(2, text)\\nvocab=list(vocab)\\nngram=MLE(3)\\nngram.fit(train,vocab)\\n'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "text=[[\"a\", \"b\", \"c\", \"d\"], [\"가\", \"다\", \"a\", \"c\"]]\n",
    "\n",
    "train, vocab=padded_everygram_pipeline(2, text)\n",
    "vocab=list(vocab)\n",
    "ngram=MLE(3)\n",
    "ngram.fit(train,vocab)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28fb781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a459fcbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "667e3ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b': 1, 'c': 1}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dict(ngram.counts[[\"a\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "932f7e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_path=\"/Users/infected4098/Downloads/Sample/origin\"\n",
    "filelist=os.listdir(d_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "61b599ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in filelist:\n",
    "    uniquefile=os.path.join(d_path, filename )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "51883cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/infected4098/Downloads/Sample/origin/BWSC217000049407.json'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniquefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "00705afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_string(filenick):\n",
    "    dummylist=[]\n",
    "    \n",
    "    with open(filenick) as f:\n",
    "        json_data=json.load(f)\n",
    "    for i in range(0, 1000):\n",
    "        try:\n",
    "        \n",
    "            kor_text=json_data[\"SJML\"][\"text\"][i][\"content\"]\n",
    "            dummylist.append(kor_text)\n",
    "        except:\n",
    "            break\n",
    "    return dummylist\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "61f3e807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def whole_pipeline(filenick, given_model):\n",
    "    dummies=file_to_string(filenick)\n",
    "    \n",
    "    for dummy in dummies:\n",
    "        \n",
    "        double_list=pre_pipeline(dummy)\n",
    "        ngrams(double_list, given_model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a1815195",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_pipeline(uniquefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "7cbb959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#순서는 \n",
    "#file_to_string으로 문자열 100개로 이루어진 리스트 만들어\n",
    "#그 리스트의 각 값들에 대해 pre_pipeline으로 doublelist를 만들어\n",
    "#model과 ngrams를 집어 넣어서 model을 학습시켜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "bebd2b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model=MLE(2)\n",
    "\n",
    "whole_pipeline(uniquefile, test_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "79eeed2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                      | 14/1535 [03:06<5:37:19, 13.31s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [181]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m tqdm(filelist):\n\u001b[1;32m      3\u001b[0m     uniquefile\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(d_path, filename)\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mwhole_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43muniquefile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [167]\u001b[0m, in \u001b[0;36mwhole_pipeline\u001b[0;34m(filenick, given_model)\u001b[0m\n\u001b[1;32m      2\u001b[0m dummies\u001b[38;5;241m=\u001b[39mfile_to_string(filenick)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dummy \u001b[38;5;129;01min\u001b[39;00m dummies:\n\u001b[0;32m----> 6\u001b[0m     double_list\u001b[38;5;241m=\u001b[39m\u001b[43mpre_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdummy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     ngrams(double_list, given_model)\n",
      "Input \u001b[0;32mIn [164]\u001b[0m, in \u001b[0;36mpre_pipeline\u001b[0;34m(stringed_text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpre_pipeline\u001b[39m(stringed_text):\n\u001b[1;32m      2\u001b[0m     listed\u001b[38;5;241m=\u001b[39mpreprocess_sent(stringed_text)\n\u001b[0;32m----> 3\u001b[0m     double\u001b[38;5;241m=\u001b[39m\u001b[43msent_to_morph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlisted\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m double\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36msent_to_morph\u001b[0;34m(lst_sent)\u001b[0m\n\u001b[1;32m     23\u001b[0m double_list\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m lst_sent:\n\u001b[0;32m---> 25\u001b[0m     listed\u001b[38;5;241m=\u001b[39m\u001b[43mokt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmorphs\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     double_list\u001b[38;5;241m.\u001b[39mappend(listed)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m double_list\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/konlpy/tag/_okt.py:78\u001b[0m, in \u001b[0;36mOkt.morphs\u001b[0;34m(self, phrase, norm, stem)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmorphs\u001b[39m(\u001b[38;5;28mself\u001b[39m, phrase, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, stem\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;124;03m\"\"\"Parse phrase to morphemes.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [s \u001b[38;5;28;01mfor\u001b[39;00m s, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mphrase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstem\u001b[49m\u001b[43m)\u001b[49m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/konlpy/tag/_okt.py:60\u001b[0m, in \u001b[0;36mOkt.pos\u001b[0;34m(self, phrase, norm, stem, join)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpos\u001b[39m(\u001b[38;5;28mself\u001b[39m, phrase, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, stem\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, join\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;124;03m\"\"\"POS tagger.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m    In contrast to other classes in this subpackage,\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03m    this POS tagger doesn't have a `flatten` option,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03m    :param join: If True, returns joined sets of morph and tag.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjki\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m                \u001b[49m\u001b[43mphrase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m                \u001b[49m\u001b[43mjpype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlang\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBoolean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m                \u001b[49m\u001b[43mjpype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlang\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBoolean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstem\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtoArray()\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m join:\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tokens]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_model=MLE(2)\n",
    "for filename in tqdm(filelist):\n",
    "    uniquefile=os.path.join(d_path, filename)\n",
    "    whole_pipeline(uniquefile, test_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c1eb06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d52bbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
