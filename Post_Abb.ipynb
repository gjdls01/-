{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43335mTQ6CnF"
      },
      "outputs": [],
      "source": [
        "!set -x \\\n",
        "&& pip install konlpy \\\n",
        "&& curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh | bash -x\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.lm import NgramCounter\n",
        "from nltk.util import ngrams\n",
        "\n",
        "from google.colab import drive\n",
        "#drive.mount('/content/gdrive')\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "from nltk.lm import MLE\n",
        "import json\n",
        "import konlpy\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "from konlpy.tag import Okt\n",
        "from konlpy.tag import Mecab, Komoran\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from itertools import combinations\n",
        "from itertools import product\n",
        "import math\n",
        "import pickle\n",
        "\"\"\"\n",
        "import sys\n",
        "sys.setrecursionlimit(10**7)\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "RiDHcYLlHQRw",
        "outputId": "4de49ff5-acbe-411c-c6e3-e56ed2f854f6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimport sys\\nsys.setrecursionlimit(10**7)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#komoran=Komoran() mecab 만 사용할 거야. 이 칸은 텍스트 데이터 전처리에 관한 것.\n",
        "mecab=Mecab()\n",
        "\n",
        "pattern_1=r\"\\([^)]*\\)\"\n",
        "pattern_2=r\"\\.{2}\"\n",
        "#json file 을 더블리스트 형태로\n",
        "def preprocess_sent(lst_text):\n",
        "    wholelist=[]\n",
        "    buf=str()\n",
        "    subkor_1=re.sub(pattern=pattern_1, repl=\"\", string=lst_text)\n",
        "    subkor_2=re.sub(pattern=pattern_2, repl=\"\", string=subkor_1)\n",
        "    clear_list=re.compile(\"[가-힣]+|\\.{1}\").findall(subkor_2)\n",
        "    for word in clear_list:\n",
        "        if word==\".\":\n",
        "            buf+=(word+\" \")\n",
        "            wholelist.append(buf)\n",
        "            buf=str()\n",
        "        \n",
        "        else:\n",
        "            buf+=(word+\" \")\n",
        "    return wholelist\n",
        "\n",
        "#더블리스트 형태를 형태소 분석된 채의 더블리스트 형태로 \n",
        "def sent_to_morph(lst_sent):\n",
        "    double_list=[]\n",
        "    for sentence in lst_sent:\n",
        "        #listed=komoran.morphs(sentence)\n",
        "        listed=mecab.morphs(sentence)\n",
        "        double_list.append(listed)\n",
        "    return double_list"
      ],
      "metadata": {
        "id": "MkQJoCakHaMh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#윗 셀에 대한 예시. 파일 하나 가지고 놀기. \n",
        "with open(\"/content/gdrive/MyDrive/origin/BWSC217000049025.json\", \"r\") as f:\n",
        "    json_data=json.load(f)\n",
        "#print(json.dumps(json_data))\n",
        "kor_text=json_data[\"SJML\"][\"text\"][1][\"content\"]\n",
        "listed=preprocess_sent(kor_text)\n",
        "double=sent_to_morph(listed)\n",
        "print(double)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBoX30CFHwKi",
        "outputId": "d552e612-e211-4884-f4fc-671553790af2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['고객', '의', '경우', '올레', '를', '단기간', '이용', '할', '수', '있', '는', '올레', '플래시', '상품', '을', '포인트', '로', '결제', '할', '수', '있', '게', '된다', '.'], ['.'], ['.'], ['는', '자사', '의', '프리미엄', '멤버십', '서비스', '인', '올레', '클럽', '회원', '을', '대상', '으로', '올레', '플래시', '상품', '을', '포인트', '인', '별로', '차감', '하', '는', '서비스', '를', '제공', '한다고', '일', '밝혔', '다', '.'], ['.'], ['.'], ['올레', '서비스', '는', '필요', '할', '때', '마다', '시간', '또는', '하루', '단위', '로', '구매', '하', '는', '서비스', '다', '.'], ['한', '시간', '은', '원', '하루', '는', '원', '이', '다', '.'], ['올레', '접속', '홈페이지', '에서', '결제', '후', '바로', '이용', '할', '수', '있', '다', '.'], ['또', '가로수길', '홍대', '삼청동', '등', '가맹점', '카페', '의', '매주', '수요일', '할인', '혜택', '을', '오', '는', '월', '말', '까지', '연장', '한다', '.'], ['하루', '에', '회', '이용', '한', '금액', '만큼', '별', '이', '차감', '된다', '.'], ['이용', '할', '수', '있', '는', '카페', '의', '위치', '등', '은', '올레', '클럽', '홈페이지', '에서', '확인', '할', '수', '있', '다', '.'], ['.'], ['.'], ['이', '외', '에', '도', '지난', '월', '부터', '데이터', '가', '부족', '한', '고객', '들', '이', '추가', '데이터', '를', '이용', '할', '수', '있', '는', '데이터', '플러스', '충전', '데이터', '를', '포인트', '로', '결제', '할', '수', '있', '다', '.'], ['.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i7VpjFjQIT33"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jVRMUl78IT1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mAMLPw0iIT0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GxMdgNnLITx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "58jEwVPuITvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v7mWZDuJITqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#학습된 모델을 바탕으로 단순히 숫자 세는 모델. 여기서는 ngramcounters 기준. \n",
        "\n",
        "\n",
        "def bigram_probs(model, pre_word, post_word):\n",
        "    word_dict=dict(model[[pre_word]])\n",
        "    wholecount=model[pre_word]\n",
        "    if wholecount!=0:\n",
        "\n",
        "      try:\n",
        "          post_count=word_dict[post_word]\n",
        "      except:\n",
        "          post_count=0\n",
        "     \n",
        "\n",
        "      emer_prob=post_count/wholecount\n",
        "\n",
        "    else:\n",
        "      emer_prob=0\n",
        "    return emer_prob\n",
        "\n",
        "def trigram_probs(model, pre_word, post_word):\n",
        "    tulist=[]\n",
        "    word_dict=dict(model[[pre_word]])\n",
        "    \n",
        "    for key in list(word_dict.keys()):\n",
        "        if key !=pre_word:\n",
        "            first_prob=bigram_probs(model, pre_word, key)\n",
        "            second_prob=bigram_probs(model, key, post_word)\n",
        "            whole_prob=first_prob*second_prob\n",
        "            if whole_prob!=0:\n",
        "                #normalization\n",
        "                whole_prob=whole_prob*2\n",
        "                tulist.append([pre_word, key, post_word, whole_prob])\n",
        "        else:\n",
        "            continue\n",
        "    return tulist"
      ],
      "metadata": {
        "id": "dH1Nx8rEIAFk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#위에서 숫자 센 걸 바탕으로 \n",
        "def canconnect(model, pre_word, post_word):\n",
        "    possiblelist=[]\n",
        "    biprob=bigram_probs(model, pre_word, post_word)\n",
        "    if biprob!=0:\n",
        "        possiblelist.append([pre_word, post_word, biprob])\n",
        "    \n",
        "    tulist=trigram_probs(model, pre_word, post_word)\n",
        "    for li in tulist:\n",
        "        possiblelist.append(li)\n",
        "    return possiblelist\n",
        "#  가능한 케이스들과 이에 대한 확률 제시. 인덱스도 만들어야 해(가능한 경우의 수 개수)\n",
        "def bigconnect(model, list_of_words):\n",
        "    dummylist=[]\n",
        "    index_list=[]\n",
        "    for i in range(len(list_of_words)-1):\n",
        "        connection=canconnect(model, list_of_words[i], list_of_words[i+1])\n",
        "        if len(connection)!=0:\n",
        "            n=len(connection)\n",
        "            index_list.append(n)\n",
        "            for possible in connection:\n",
        "                dummylist.append(possible)\n",
        "    \n",
        "        else:\n",
        "            print(\"connection failed\")\n",
        "            break\n",
        "    return dummylist, index_list\n"
      ],
      "metadata": {
        "id": "xA7LUSgRIZJJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#위에서 주어진 dummylist 와 index_list를 바탕으로 깔끔한 출력을 위한 함수들.\n",
        "def process(model, list_of_words):\n",
        "    doublelists, index=bigconnect(model, list_of_words)\n",
        "    for indexes in range(len(doublelists)):\n",
        "        doublelists[indexes]=tuple(doublelists[indexes])\n",
        "    return doublelists, index\n",
        "\n",
        "def separate_connection(model,list_of_words):\n",
        "    newconlist=[]\n",
        "    pro_doublelists, pro_index=process(model, list_of_words)\n",
        "    end, start=0, 0\n",
        "    for i in pro_index:\n",
        "        end+=i\n",
        "        newconlist.append(pro_doublelists[start:end])\n",
        "\n",
        "        start+=i\n",
        "    return newconlist\n",
        "  \n",
        "\n",
        "#확률값이 너무 작아서 별로니 이를 예쁘게. 이 점수의 최댓값은 10000. 최저는 0. \n",
        "def pretty_prob(prob):\n",
        "  prob=10000*prob\n",
        "  prob=round(prob, 4)\n",
        "  return prob  \n",
        "\n",
        "def make_it_one(model, list_of_words):\n",
        "    wholeconcat=[]\n",
        "    wholeprob=1.0\n",
        "    newlist=separate_connection(model, list_of_words)\n",
        "    #separate connection을 거치면 \n",
        "    maybe_one=list(product(*newlist))\n",
        "    for i in maybe_one:\n",
        "        for index in range(len(i)):\n",
        "            wholeconcat.append(i[index][:-2])\n",
        "            wholeprob*=i[index][-1]\n",
        "        wholeconcat.append(tuple(list_of_words[-1]))\n",
        "        wholeconcat.append(pretty_prob(wholeprob))\n",
        "        wholeprob=1.0\n",
        "    return wholeconcat\n",
        "\n"
      ],
      "metadata": {
        "id": "PPBVqpBJJf5H"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6Es9Yx86JfzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_model=NgramCounter()\n",
        "def ngrams_mine(double_list, model):\n",
        "  text_unigrams = [ngrams(sent, 1) for sent in double_list]\n",
        "  text_bigrams  = [ngrams(sent, 2) for sent in double_list]\n",
        "  model.update(text_unigrams+text_bigrams)\n",
        "  return model\n",
        "\n",
        "\n",
        "#지금부터는 예시\n",
        "text=[[\"a\", \"b\", \"c\", \"d\"], [\"d\", \"w\", \"c\", \"a\"], [\"c\", \"b\", \"d\", \"a\"]]\n",
        "ngrams_mine(text, n_model)\n",
        "text2=[[\"a\", \"b\", \"c\", \"D\"], [\"d\", \"K\", \"c\", \"a\"], [\"c\", \"b\", \"C\", \"a\"]]\n",
        "ngrams_mine(text, n_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNYp5IgSJfxP",
        "outputId": "fde16327-ca4f-4d70-dd17-ae6724d1d289"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<nltk.lm.counter.NgramCounter at 0x7f9bc2f7a650>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#학습 phase. 일단 그냥 전체 데이터에 대한 리스트질을 해보자\n",
        "#파일 받아서 전체과정\n",
        "def file_to_string(filenick):\n",
        "    dummylist=[]\n",
        "\n",
        "    with open(filenick) as f:\n",
        "        json_data=json.load(f)\n",
        "    for i in range(0, 1000):\n",
        "        try:\n",
        "        \n",
        "            kor_text=json_data[\"SJML\"][\"text\"][i][\"content\"]\n",
        "            dummylist.append(kor_text)\n",
        "        except:\n",
        "            break\n",
        "    return dummylist\n",
        "\n",
        "def pre_pipeline(stringed_text):\n",
        "    listed=preprocess_sent(stringed_text)\n",
        "    double=sent_to_morph(listed)\n",
        "    \n",
        "    return double\n",
        "\n",
        "def whole_pipeline(filenick, given_model):\n",
        "    dummies=file_to_string(filenick)\n",
        "    \n",
        "    for dummy in dummies:\n",
        "        \n",
        "        double_list=pre_pipeline(dummy)\n",
        "        ngrams_mine(double_list, given_model)"
      ],
      "metadata": {
        "id": "Tkw0LwfoJf3N"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#실제 학습 phase\n",
        "\"\"\"\n",
        "d_path=\"미정\"\n",
        "filelist=os.listdir(d_path)\n",
        "for filename in filelist:\n",
        "    uniquefile=os.path.join(d_path, filename )\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "A3nu5LodMX7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HkpMGBjtP1Mm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#생성된 객체 저장하는 시스템 만들기 (pickle 활용)\n",
        "\"\"\"\n",
        "with open(\"/content/gdrive/MyDrive/origin/testjames.p\", \"wb\") as file:\n",
        "  pickle.dump(n_model, file)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "I0EZXTRBJfvP"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WwBZ4Kp1JftF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#생성된 객체 불러오는 시스템 만들기 (pickle 활용)\n",
        "\"\"\"\n",
        "with open(\"/content/gdrive/MyDrive/origin/testjames.p\", \"rb\") as file:\n",
        "  maybe=pickle.load(file)\n",
        "\n",
        "maybe.N()\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "mZBiuolcITgE",
        "outputId": "94c1a503-91c5-4bfc-a017-9a1ced200005"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nwith open(\"/content/gdrive/MyDrive/origin/testjames.p\", \"rb\") as file:\\n  maybe=pickle.load(file)\\n\\nmaybe.N()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOPaOHRSMWYz",
        "outputId": "e50d2af9-68af-448d-b0b2-b95172a7213c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3fz06GP-JfpX"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}